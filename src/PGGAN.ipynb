{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cwYWBMXKjeI"
   },
   "source": [
    "# **Depedencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9cRMAhzP0J1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PMzQ_SQ3KBP"
   },
   "source": [
    "# **Project Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShbJst2WZyGv"
   },
   "outputs": [],
   "source": [
    "DATAROOT = \"data\"\n",
    "lr = 0.001\n",
    "input_code_size = 128\n",
    "NUM_CHANNELS = 128\n",
    "BATCH_SIZE = 4 #Batch Size during 1 iteration\n",
    "START_SIZE = 1 #At which size do we start the programm\n",
    "NUM_ITER = 250000 #How many iterations in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Stu1uiX2IkY"
   },
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9l4OWxE2MOJ"
   },
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "\n",
    "# This time we need to create responsive dataloader that will adapt itself depending on\n",
    "# the size that we are currently treating\n",
    "\n",
    "def pokemon_loader_folder(path):\n",
    "    def loader(transform, image_size):\n",
    "        data = datasets.ImageFolder(path, transform=transform)\n",
    "        if image_size <= 64:\n",
    "            data_loader = DataLoader(data, shuffle=True, batch_size=BATCH_SIZE,\n",
    "                                     num_workers=4)\n",
    "        else:\n",
    "            data_loader = DataLoader(data, shuffle=True, batch_size=BATCH_SIZE//2,\n",
    "                         num_workers=4)\n",
    "        return data_loader\n",
    "    return loader\n",
    "\n",
    "def create_loader_depending_on_image_size(dataloader, image_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size+int(image_size*0.2)+1),\n",
    "        transforms.RandomCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    loader = dataloader(transform, image_size)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyDYDUqASsPg"
   },
   "outputs": [],
   "source": [
    "def upscale(feat):\n",
    "    return F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating the Equalized Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * sqrt(2 / fan_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        del module._parameters[name]\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)\n",
    "\n",
    "\n",
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module\n",
    "\n",
    "\n",
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class EqualConvTranspose2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.ConvTranspose2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQC81NK_jIzN"
   },
   "source": [
    "# **Creating the Convolution Block**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LhbtZEcgSeB-"
   },
   "outputs": [],
   "source": [
    "class ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        convs = [EqualConv2d(in_channel, out_channel, kernel1, padding=pad1)]\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "        convs.append(EqualConv2d(out_channel, out_channel, kernel2, padding=pad2))\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.conv = nn.Sequential(*convs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02LmhEHVT-S1"
   },
   "source": [
    "# **Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GF6Ii3SrSuek"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_code_dim=128, in_channel=128):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_code_dim\n",
    "        self.input_layer = nn.Sequential(\n",
    "            EqualConvTranspose2d(input_code_dim, in_channel, 4, 1, 0),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.progression_4 = ConvolutionBlock(in_channel, in_channel, 3, 1)\n",
    "        self.progression_8 = ConvolutionBlock(in_channel, in_channel, 3, 1)\n",
    "        self.progression_16 = ConvolutionBlock(in_channel, in_channel, 3, 1)\n",
    "        self.progression_32 = ConvolutionBlock(in_channel, in_channel, 3, 1)\n",
    "        self.progression_64 = ConvolutionBlock(in_channel, in_channel//2, 3, 1)\n",
    "        self.progression_128 = ConvolutionBlock(in_channel//2, in_channel//4, 3, 1)\n",
    "\n",
    "        self.to_rgb_8 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_16 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_32 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_64 = EqualConv2d(in_channel//2, 3, 1)\n",
    "        self.to_rgb_128 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        \n",
    "        self.max_step = 5\n",
    "        \n",
    "    # This allows the generator to multiply the output of the previous layer, in order\n",
    "    # To make it a x2 sized picture\n",
    "    def progress(self, feat, module):\n",
    "        out = F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        out = module(out)\n",
    "        return out\n",
    "\n",
    "    def output(self, feat1, feat2, module1, module2, alpha):\n",
    "        # Depending on the alpha, we add progressively a new layer \n",
    "        if 0 <= alpha < 1:\n",
    "            skip_rgb = upscale(module1(feat1))\n",
    "            out = (1-alpha)*skip_rgb + alpha*module2(feat2)\n",
    "        else:\n",
    "            out = module2(feat2)\n",
    "        return out\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        if step > self.max_step:\n",
    "            step = self.max_step\n",
    "\n",
    "        out_4 = self.input_layer(input.view(-1, self.input_dim, 1, 1))\n",
    "        out_4 = self.progression_4(out_4)\n",
    "        out_8 = self.progress(out_4, self.progression_8)\n",
    "        if step==1:\n",
    "            return self.to_rgb_8(out_8)\n",
    "        \n",
    "        out_16 = self.progress(out_8, self.progression_16)\n",
    "        if step==2:\n",
    "            return self.output( out_8, out_16, self.to_rgb_8, self.to_rgb_16, alpha )\n",
    "        \n",
    "        out_32 = self.progress(out_16, self.progression_32)\n",
    "        if step==3:\n",
    "            return self.output( out_16, out_32, self.to_rgb_16, self.to_rgb_32, alpha )\n",
    "\n",
    "        out_64 = self.progress(out_32, self.progression_64)\n",
    "        if step==4:\n",
    "            return self.output( out_32, out_64, self.to_rgb_32, self.to_rgb_64, alpha )\n",
    "        \n",
    "        out_128 = self.progress(out_64, self.progression_128)\n",
    "        if step==5:\n",
    "            return self.output( out_64, out_128, self.to_rgb_64, self.to_rgb_128, alpha )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FgpsJ3_UClf"
   },
   "source": [
    "# **Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RNmYVEKS_GK"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feat_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList([ConvolutionBlock(feat_dim//4, feat_dim//4, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim//4, feat_dim//2, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim//2, feat_dim, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvolutionBlock(feat_dim+1, feat_dim, 3, 1, 4, 0)])\n",
    "\n",
    "        self.from_rgb = nn.ModuleList([EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//2, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1)])\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(feat_dim, 1)\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        for i in range(step, -1, -1):\n",
    "            index = self.n_layer - i - 1\n",
    "\n",
    "            if i == step:\n",
    "                out = self.from_rgb[index](input)\n",
    "\n",
    "            if i == 0:\n",
    "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                mean_std = out_std.mean()\n",
    "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "            out = self.progression[index](out)\n",
    "\n",
    "            if i > 0:\n",
    "                out = F.interpolate(out, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "                if i == step and 0 <= alpha < 1:\n",
    "                    skip_rgb = F.interpolate(input, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "        out = out.squeeze(2).squeeze(2)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjB1FOSARe4Z"
   },
   "outputs": [],
   "source": [
    "def train(generator, discriminator, start_size, loader, num_iter=50000):\n",
    "    step = start_size # can be 1 = 8, 2 = 16, 3 = 32, 4 = 64, 5 = 128\n",
    "    data_loader = create_loader_depending_on_image_size(loader, 4 * 2 ** step)\n",
    "    dataset = iter(data_loader)\n",
    "\n",
    "    num_iter_remain = num_iter - (num_iter//5)*(step-1)\n",
    "\n",
    "    # Progress Bar \n",
    "    pbar = tqdm(range(num_iter_remain))\n",
    "\n",
    "    disc_loss_val = 0\n",
    "    gen_loss_val = 0\n",
    "    grad_loss_val = 0\n",
    "\n",
    "    # Creating Saving Folder\n",
    "    log_folder = 'log_folder'\n",
    "    \n",
    "    os.mkdir(log_folder)\n",
    "    # To store the pictures\n",
    "    os.mkdir(log_folder+'/sample')\n",
    "\n",
    "    # Log for Discriminator & Generator Loss Value\n",
    "    log_file_name = os.path.join(log_folder, 'generator_discriminator_values')\n",
    "    log_file = open(log_file_name, 'w')\n",
    "    log_file.write('generator,discriminator,gradient,alpha\\n')\n",
    "    log_file.close()\n",
    "\n",
    "    # Initializing the parameters\n",
    "    cuda0=torch.device('cuda:0')\n",
    "    alpha = 0\n",
    "    one = torch.tensor(1, dtype=torch.float, device=cuda0)\n",
    "    mone = one * -1\n",
    "    iteration = 0\n",
    "\n",
    "    for i in pbar:\n",
    "        # Clears up old gradients\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        # Alpha is the evolution rate, that will progressively\n",
    "        # add the new output produced by the new layer added on top of the other\n",
    "        # The more we enter in the iteration \n",
    "        alpha = min(1, (2/(num_iter//5)) * iteration)\n",
    "\n",
    "        # If the number of iteration goes over the number 1/5 of the total iteration\n",
    "        # We go to the next step and increase the size of the produced image.\n",
    "        if iteration > num_iter//5:\n",
    "            alpha = 0\n",
    "            iteration = 0\n",
    "            step += 1\n",
    "            data_loader = create_loader_depending_on_image_size(loader, 4 * 2 ** step)\n",
    "            dataset = iter(data_loader)\n",
    "\n",
    "        try:\n",
    "            real_image, label = next(dataset)\n",
    "        except (OSError, StopIteration):\n",
    "            # When the dataset iterator is over, we need to reload it\n",
    "            dataset = iter(data_loader)\n",
    "            real_image, label = next(dataset)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        ### 1. train Discriminator\n",
    "        ## Takes a new image and compare the prediction vs \n",
    "        b_size = real_image.size(0)\n",
    "        real_image = real_image.to(device)\n",
    "        label = label.to(device)\n",
    "        real_predict = discriminator(real_image, step=step, alpha=alpha)\n",
    "        real_predict = real_predict.mean() - 0.001 * (real_predict ** 2).mean()\n",
    "        real_predict.backward(mone)\n",
    "\n",
    "        # sample input data: vector for Generator\n",
    "        # We generate a fake vector\n",
    "        gen_z = torch.randn(b_size, input_code_size).to(device)\n",
    "\n",
    "        fake_image = generator(gen_z, step=step, alpha=alpha)\n",
    "        fake_predict = discriminator(fake_image.detach(), step=step, alpha=alpha)\n",
    "        fake_predict = fake_predict.mean()\n",
    "        fake_predict.backward(one)\n",
    "\n",
    "\n",
    "        eps = torch.rand(b_size, 1, 1, 1).to(device)\n",
    "        x_hat = eps * real_image.data + (1 - eps) * fake_image.detach().data\n",
    "        x_hat.requires_grad = True\n",
    "        hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "        grad_x_hat = grad(outputs=hat_predict.sum(), inputs=x_hat, create_graph=True)[0]\n",
    "        grad_penalty = ((grad_x_hat.view(grad_x_hat.size(0), -1).norm(2, dim=1) - 1)**2).mean()\n",
    "        grad_penalty = 10 * grad_penalty\n",
    "        grad_penalty.backward()\n",
    "        grad_loss_val += grad_penalty.item()\n",
    "        disc_loss_val += (real_predict - fake_predict).item()\n",
    "\n",
    "        # Take a step based on the gradient, for the optimizer\n",
    "        d_optimizer.step()\n",
    "\n",
    "        ### 2. train Generator\n",
    "        generator.zero_grad()\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "        loss = -predict.mean()\n",
    "        gen_loss_val += loss.item()\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        g_optimizer.step()\n",
    "        accumulate(g_running, generator)\n",
    "\n",
    "        # Save the images into a folder\n",
    "        if (i + 1) % 1000 == 0 or i==0:\n",
    "            with torch.no_grad():\n",
    "                images = g_running(torch.randn(5 * 10, input_code_size).to(device), step=step, alpha=alpha).data.cpu()\n",
    "\n",
    "                utils.save_image(\n",
    "                    images,\n",
    "                    f'{log_folder}/sample/{str(i + 1).zfill(6)}.png',\n",
    "                    nrow=10,\n",
    "                    normalize=True,\n",
    "                    range=(-1, 1))\n",
    "        \n",
    "        # Save the Generator Loss Value, Discriminator Loss Value and the Alpha value every 500 iterations\n",
    "        if (i+1)%500 == 0:\n",
    "            state_msg = (f'{i + 1}; G: {gen_loss_val/500:.3f}; D: {disc_loss_val/500:.3f};'\n",
    "                f' Grad: {grad_loss_val/500:.3f}; Alpha: {alpha:.3f}')\n",
    "            \n",
    "            log_file = open(log_file_name, 'a+')\n",
    "            new_line = \"%.5f,%.5f,%.5f,%.5f\\n\"%(gen_loss_val/500, disc_loss_val/500,grad_loss_val/500, alpha)\n",
    "            log_file.write(new_line)\n",
    "            log_file.close()\n",
    "\n",
    "            disc_loss_val = 0\n",
    "            gen_loss_val = 0\n",
    "            grad_loss_val = 0\n",
    "\n",
    "            print(state_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4NBS7X3OGLlk"
   },
   "source": [
    "# **Running the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T619XIq1Q9hy"
   },
   "outputs": [],
   "source": [
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b22jBAjBp6uj",
    "outputId": "395f3e9d-726b-4989-c8ea-50d6ae2ffb6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 504/250000 [00:15<2:19:10, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500; G: -0.054; D: 0.056; Grad: 0.069; Alpha: 0.020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1006/250000 [00:32<2:07:15, 32.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000; G: 0.356; D: -0.017; Grad: 0.062; Alpha: 0.040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1504/250000 [00:47<2:32:10, 27.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500; G: 0.511; D: 0.068; Grad: 0.059; Alpha: 0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2007/250000 [01:02<2:03:22, 33.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000; G: 0.720; D: 0.231; Grad: 0.078; Alpha: 0.080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2506/250000 [01:18<2:04:04, 33.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500; G: 0.899; D: 0.254; Grad: 0.097; Alpha: 0.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3004/250000 [01:33<2:02:30, 33.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000; G: 0.769; D: 0.222; Grad: 0.085; Alpha: 0.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3504/250000 [01:48<2:09:03, 31.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500; G: 1.210; D: 0.399; Grad: 0.101; Alpha: 0.140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4007/250000 [02:04<1:57:18, 34.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000; G: 1.346; D: 0.395; Grad: 0.102; Alpha: 0.160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4503/250000 [02:21<3:53:31, 17.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500; G: 1.170; D: 0.348; Grad: 0.093; Alpha: 0.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5004/250000 [02:39<2:19:23, 29.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000; G: 0.902; D: 0.263; Grad: 0.077; Alpha: 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5506/250000 [02:54<1:55:18, 35.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500; G: 0.586; D: 0.151; Grad: 0.080; Alpha: 0.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6006/250000 [03:08<1:53:20, 35.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000; G: 0.206; D: 0.129; Grad: 0.069; Alpha: 0.240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6506/250000 [03:22<2:06:31, 32.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500; G: 0.464; D: 0.109; Grad: 0.065; Alpha: 0.260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7006/250000 [03:36<1:51:45, 36.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000; G: 0.342; D: 0.116; Grad: 0.067; Alpha: 0.280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7506/250000 [03:50<1:56:10, 34.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500; G: 0.196; D: 0.056; Grad: 0.063; Alpha: 0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8007/250000 [04:06<1:55:22, 34.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000; G: 0.202; D: 0.063; Grad: 0.056; Alpha: 0.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 8507/250000 [04:21<1:54:27, 35.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8500; G: 0.462; D: 0.068; Grad: 0.055; Alpha: 0.340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 9005/250000 [04:36<2:10:06, 30.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000; G: 0.183; D: 0.096; Grad: 0.060; Alpha: 0.360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9506/250000 [04:53<2:10:40, 30.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500; G: 0.416; D: 0.125; Grad: 0.059; Alpha: 0.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10005/250000 [05:08<1:52:57, 35.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000; G: 0.433; D: 0.116; Grad: 0.058; Alpha: 0.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10505/250000 [05:22<1:50:16, 36.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500; G: 0.277; D: 0.087; Grad: 0.060; Alpha: 0.420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 11006/250000 [05:37<2:01:28, 32.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000; G: 0.185; D: 0.117; Grad: 0.063; Alpha: 0.440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11506/250000 [05:53<1:53:58, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11500; G: 0.460; D: 0.123; Grad: 0.064; Alpha: 0.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 12001/250000 [06:08<2:13:49, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000; G: 0.339; D: 0.104; Grad: 0.061; Alpha: 0.480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 12504/250000 [06:23<1:48:41, 36.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500; G: 0.323; D: 0.081; Grad: 0.060; Alpha: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13004/250000 [06:37<2:06:02, 31.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000; G: 0.231; D: 0.086; Grad: 0.058; Alpha: 0.520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13505/250000 [06:51<1:48:29, 36.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13500; G: 0.329; D: 0.076; Grad: 0.056; Alpha: 0.540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14005/250000 [07:05<1:48:59, 36.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000; G: 0.507; D: 0.082; Grad: 0.054; Alpha: 0.560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14506/250000 [07:20<1:47:49, 36.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14500; G: 0.405; D: 0.074; Grad: 0.053; Alpha: 0.580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15006/250000 [07:34<1:49:43, 35.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000; G: 0.502; D: 0.097; Grad: 0.057; Alpha: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 15504/250000 [07:49<2:02:08, 32.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15500; G: 0.202; D: 0.087; Grad: 0.058; Alpha: 0.620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 16003/250000 [08:04<2:22:18, 27.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000; G: 0.220; D: 0.085; Grad: 0.057; Alpha: 0.640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16505/250000 [08:19<2:08:11, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16500; G: 0.301; D: 0.099; Grad: 0.057; Alpha: 0.660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17005/250000 [08:34<1:55:23, 33.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000; G: 0.368; D: 0.101; Grad: 0.057; Alpha: 0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17505/250000 [08:49<1:56:31, 33.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17500; G: 0.326; D: 0.085; Grad: 0.063; Alpha: 0.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18005/250000 [09:05<1:53:26, 34.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000; G: 0.350; D: 0.079; Grad: 0.055; Alpha: 0.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 18504/250000 [09:21<1:58:10, 32.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18500; G: 0.289; D: 0.077; Grad: 0.056; Alpha: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19004/250000 [09:36<2:00:20, 31.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19000; G: 0.270; D: 0.054; Grad: 0.055; Alpha: 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19506/250000 [09:52<2:19:11, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19500; G: 0.182; D: 0.069; Grad: 0.053; Alpha: 0.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20007/250000 [10:08<1:51:28, 34.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000; G: 0.344; D: 0.066; Grad: 0.054; Alpha: 0.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20500/250000 [10:24<2:09:21, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20500; G: 0.293; D: 0.102; Grad: 0.060; Alpha: 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 21004/250000 [10:41<2:34:22, 24.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000; G: 0.396; D: 0.087; Grad: 0.055; Alpha: 0.840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 21506/250000 [10:56<1:47:38, 35.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21500; G: 0.226; D: 0.076; Grad: 0.054; Alpha: 0.860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22007/250000 [11:12<1:49:30, 34.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000; G: 0.427; D: 0.075; Grad: 0.058; Alpha: 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22505/250000 [11:29<2:15:57, 27.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500; G: 0.308; D: 0.077; Grad: 0.055; Alpha: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23003/250000 [11:45<1:57:53, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23000; G: 0.195; D: 0.093; Grad: 0.057; Alpha: 0.920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 23506/250000 [12:00<1:43:36, 36.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23500; G: 0.208; D: 0.086; Grad: 0.058; Alpha: 0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24007/250000 [12:15<1:47:38, 34.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000; G: 0.320; D: 0.067; Grad: 0.054; Alpha: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24507/250000 [12:29<1:42:09, 36.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24500; G: 0.285; D: 0.096; Grad: 0.055; Alpha: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25007/250000 [12:43<1:45:10, 35.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000; G: 0.251; D: 0.074; Grad: 0.053; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25507/250000 [12:57<1:37:28, 38.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25500; G: 0.311; D: 0.082; Grad: 0.052; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 26004/250000 [13:11<2:20:39, 26.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26000; G: 0.321; D: 0.076; Grad: 0.055; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 26507/250000 [13:25<1:46:32, 34.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26500; G: 0.265; D: 0.108; Grad: 0.061; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27006/250000 [13:40<2:18:24, 26.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27000; G: 0.415; D: 0.080; Grad: 0.055; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 27506/250000 [13:55<1:43:51, 35.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27500; G: 0.323; D: 0.096; Grad: 0.058; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 28006/250000 [14:10<1:51:06, 33.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000; G: 0.282; D: 0.079; Grad: 0.052; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 28506/250000 [14:24<1:46:30, 34.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28500; G: 0.432; D: 0.088; Grad: 0.057; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29005/250000 [14:40<1:50:10, 33.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29000; G: 0.225; D: 0.074; Grad: 0.054; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29504/250000 [14:55<1:45:41, 34.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29500; G: 0.256; D: 0.086; Grad: 0.053; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30005/250000 [15:11<1:53:31, 32.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000; G: 0.227; D: 0.067; Grad: 0.051; Alpha: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30059/250000 [15:13<2:09:50, 28.23it/s]"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "generator = Generator(in_channel=NUM_CHANNELS, input_code_dim=input_code_size).to(device)\n",
    "discriminator = Discriminator(feat_dim=NUM_CHANNELS).to(device)\n",
    "g_running = Generator(in_channel=NUM_CHANNELS, input_code_dim=input_code_size).to(device)\n",
    "\n",
    "g_running.train(False)\n",
    "\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.0, 0.99))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.0, 0.99))\n",
    "\n",
    "accumulate(g_running, generator, 0)\n",
    "\n",
    "loader = pokemon_loader_folder(DATAROOT)\n",
    "\n",
    "train(generator, discriminator, START_SIZE, loader, NUM_ITER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Générer ses propres Pokemons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = g_running(torch.randn(5 * 10, input_code_size).to(device), step=step, alpha=alpha).data.cpu()\n",
    "images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Etude des Loss et Gradient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.join(os.getcwd(), 'log_folder/generator_discriminator_values')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    logs_dict = {}\n",
    "    titles = next(file).rstrip('\\n').split(',')\n",
    "    for title in titles:\n",
    "        logs_dict[title] = []\n",
    "    file_reader = file.readlines()\n",
    "    for line in file_reader:\n",
    "        values = list(map(float, line.rstrip('\\n').split(',')))\n",
    "        for i in range(len(titles)):\n",
    "            logs_dict[titles[i]].append(values[i])\n",
    "\n",
    "X = list(range(500, 53500, 500))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(X, logs_dict['generator'],label=\"G\")\n",
    "plt.plot(X, logs_dict['discriminator'],label=\"D\")\n",
    "plt.plot(X, logs_dict['alpha'],label=\"A\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Gradient values during training\")\n",
    "plt.plot(X, logs_dict['gradient loss'],label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPKoZ7p/VjOcsZO6KO/Hg/4",
   "collapsed_sections": [],
   "mount_file_id": "1VjABenSZSHx_zRVKj3BmjZ3_gBt4G2_U",
   "name": "PokemonPCGAN.ipynb",
   "provenance": [
    {
     "file_id": "1TPpbhIBbKnI9QFOEPNkOZC1MScg-VaBb",
     "timestamp": 1582531962166
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
