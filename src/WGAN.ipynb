{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "WGAN",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4V8YFVpaJXV",
        "colab_type": "text"
      },
      "source": [
        "# Pokemon Generation using GANs [WGAN]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hqgjHxzbAI_",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5c6BAxk23Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.autograd as autograd\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf-b1iLVasDk",
        "colab_type": "text"
      },
      "source": [
        "## Connect to drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9XTdnYCbYxt",
        "colab_type": "text"
      },
      "source": [
        "In order to use pokemon data you need to get data from [this Github project](https://github.com/rileynwong/pokemon-images-dataset-by-type).\\\n",
        "Then you need to convert them to `.png` and save them in a file nammed `data` in your Google Drive.\\\n",
        "**Do not forget to change the `prefix` variable to the path to your data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt3gR5kv3Mb6",
        "colab_type": "code",
        "outputId": "63193e65-6d34-4b1f-f652-de99a4d7b6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "prefix = \"gdrive/My Drive/ECP/DL\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud0WlVyEgLjO",
        "colab_type": "text"
      },
      "source": [
        "## Parameters input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zavRyc9YQX-3",
        "colab_type": "code",
        "outputId": "6fff8491-5a06-4643-8756-cf1a7ff5a164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Set the seed manually or randomly\n",
        "\n",
        "seed = 999 # Use 'random.randint(1, 10000)' to deactivate reproductability\n",
        "print(\"seed: \", seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed:  999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0734c32a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz8rWkTI23Z9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Size of z latent vector# Root directory of the dataset\n",
        "PATH_DATA = os.path.join(prefix, \"data\")\n",
        "PATH_NOTEBOOK = os.path.join(prefix, \"GAN_WASSERSTEIN\")\n",
        "# Number of channels per image\n",
        "IMG_N_CHANNELS = 3 #@param {type: \"integer\", default: 3}\n",
        "# Rescale size before random crop\n",
        "IMG_RESCALE_SIZE = 160 #@param {type: \"integer\", default: 180}\n",
        "# Final size of the image\n",
        "IMG_SIZE = 128 #@param {type: \"integer\", default: 128}\n",
        "# Number of workers for dataloader\n",
        "N_WORKERS =  8#@param {type: \"integer\", default: 2}\n",
        "\n",
        "# Size of the latent vector\n",
        "LATENT_VECTOR_SIZE =  64 #@param {type:'integer', default: 64}\n",
        "# Size of the base feature map in generator\n",
        "G_FEATURE_SIZE = 256 #@param {type:'integer', default: 64}\n",
        "# Size of the base feature map in discriminator\n",
        "D_FEATURE_SIZE =  256#@param {type:'integer', default: 64}\n",
        "\n",
        "# Batch size during training\n",
        "BATCH_SIZE = 64 #@param {type:'integer', default: 64}\n",
        "# Number of training epochs\n",
        "NUM_EPOCHS = 200 #@param {type:'integer', default: 300}\n",
        "# Learning rate for optimizers\n",
        "LEARNING_RATE = 0.0002  #@param {type:'number', default: 0.00005}\n",
        "# Number of training iterations for the discriminator befor training the generator\n",
        "D_N_TRAIN =  5# @param {type:'integer', default:5}\n",
        "# Clip value for weights\n",
        "CLIP_VALUE = 0.01 #@param {type:'number', default: 0.01}\n",
        "# Adam optimizer parameters\n",
        "BETA1 = 0.5 #@param {type: 'number', default: 0.5}\n",
        "BETA2 = 0.999 #@param {type: 'number', default: 0.999}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZD7N7KCmdXl",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01Jd8b4A23aM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We use a `torch.utils.data.DataLoader` to handle the data. That way we can easily apply random transformation to each batch at every epoch.\n",
        "\n",
        "# Create the dataset\n",
        "dataset = datasets.ImageFolder(root=PATH_DATA,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(IMG_RESCALE_SIZE),\n",
        "                               transforms.RandomCrop(IMG_SIZE),\n",
        "                               transforms.RandomHorizontalFlip(),\n",
        "                               transforms.RandomRotation(20, fill=(255, 255, 255)),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE,\n",
        "                                         shuffle=True, num_workers=N_WORKERS)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bjvHFdrmlZq",
        "colab_type": "code",
        "outputId": "05d7dcd8-7ad6-420f-f1b0-6fcdefb6fe50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Uses the Colab GPU as a device if available\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wp6pP2Cmn4p",
        "colab_type": "code",
        "outputId": "42e3031c-a907-44f7-cf76-efa87aa8d142",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Plots a sample of the processed data used for the training.\n",
        "\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:32], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f06e0414a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAAoYhkjnjoy",
        "colab_type": "text"
      },
      "source": [
        "## Models definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YOAu9p623aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator definition\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    def conv_block(in_features, out_features, normalize=True):\n",
        "      layers = [nn.ConvTranspose2d(in_features, out_features, 3, 2, 1, 1, bias=False)]\n",
        "      if normalize:\n",
        "        layers.append(nn.BatchNorm2d(out_features, 0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "      return layers\n",
        "\n",
        "    self.conv_blocks = nn.Sequential(\n",
        "        *conv_block(G_FEATURE_SIZE, G_FEATURE_SIZE // 2),\n",
        "        *conv_block(G_FEATURE_SIZE // 2, G_FEATURE_SIZE // 4),\n",
        "        *conv_block(G_FEATURE_SIZE // 4 , G_FEATURE_SIZE // 8),\n",
        "        *conv_block(G_FEATURE_SIZE // 8 , G_FEATURE_SIZE // 16),\n",
        "    )\n",
        "\n",
        "    self.in_block = nn.Sequential(\n",
        "        nn.Linear(LATENT_VECTOR_SIZE, G_FEATURE_SIZE // 2 * 4 * 4, bias=False),\n",
        "        nn.BatchNorm1d(G_FEATURE_SIZE // 2 * 4 * 4, 0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(G_FEATURE_SIZE // 2 * 4 * 4, G_FEATURE_SIZE * 4 * 4, bias=False),\n",
        "        nn.BatchNorm1d(G_FEATURE_SIZE * 4 * 4, 0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True)\n",
        "    )\n",
        "\n",
        "    self.out_block = nn.Sequential(\n",
        "        nn.ConvTranspose2d(G_FEATURE_SIZE // 16, 3, 3, 2, 1, 1, bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    z = z.view(-1, LATENT_VECTOR_SIZE)\n",
        "    x = self.in_block(z)\n",
        "    x = x.view(-1, G_FEATURE_SIZE, 4, 4)\n",
        "    x = self.conv_blocks(x)\n",
        "    img = self.out_block(x)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdtN0Gv123aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Discriminator definition\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    def conv_block(in_features, out_features, normalize=True):\n",
        "      layers = [nn.Conv2d(in_features, out_features, 3, 2, 1, bias=True)]\n",
        "      if normalize:\n",
        "        layers.append(nn.BatchNorm2d(out_features, 0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "      return layers\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        *conv_block(IMG_N_CHANNELS, D_FEATURE_SIZE // 2),\n",
        "        *conv_block(D_FEATURE_SIZE // 2 , D_FEATURE_SIZE // 4),\n",
        "        *conv_block(D_FEATURE_SIZE // 4, D_FEATURE_SIZE // 8),\n",
        "        *conv_block(D_FEATURE_SIZE // 8, D_FEATURE_SIZE // 16),\n",
        "        *conv_block(D_FEATURE_SIZE // 16, D_FEATURE_SIZE // 32),\n",
        "    )\n",
        "\n",
        "    self.out_block = nn.Sequential(\n",
        "        nn.Linear(D_FEATURE_SIZE // 32 * 4 * 4, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, img):\n",
        "    x = self.model(img)\n",
        "    x = x.view(-1, D_FEATURE_SIZE // 32 * 4 * 4)\n",
        "    out = self.out_block(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXyaxbLfoqm0",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaPsqSYN23ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the generator and the discriminator\n",
        "\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fSTzxcU23aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates the optimizers\n",
        "\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(BETA1, BETA2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4uSsFYPnPVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.randn(real_samples.size(0), 1, 1, 1, device=device)\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = torch.full((real_samples.shape[0], 1), 1.0, device=device, requires_grad=False)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQJ2fzr23a0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, LATENT_VECTOR_SIZE, 1, 1, device=device)\n",
        "img_list = []\n",
        "\n",
        "batches_done = 0\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "  for i, (imgs, _) in enumerate(dataloader, 0):\n",
        "\n",
        "    # Configure input\n",
        "    real_imgs = imgs.to(device)\n",
        "    b_size = real_imgs.size(0)\n",
        "    # ---------------------\n",
        "    #  Train Discriminator\n",
        "    # ---------------------\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "\n",
        "    # Sample noise as generator input\n",
        "    z = torch.randn(b_size, LATENT_VECTOR_SIZE, 1, 1, device=device)\n",
        "\n",
        "    # Generate a batch of images\n",
        "    fake_imgs = generator(z)\n",
        "\n",
        "    real_validity = discriminator(real_imgs)\n",
        "    fake_validity = discriminator(fake_imgs)\n",
        "    # compute graient penalty\n",
        "    gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
        "    # Adversarial loss\n",
        "    loss_D = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gradient_penalty\n",
        "    loss_D.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "\n",
        "    # Train the generator every n_critic iterations\n",
        "    if i % D_N_TRAIN == 0:\n",
        "      # -----------------\n",
        "      #  Train Generator\n",
        "      # -----------------\n",
        "\n",
        "      \n",
        "      # Generate a batch of images\n",
        "      gen_imgs = generator(z)\n",
        "      # Adversarial loss\n",
        "      loss_G = -torch.mean(discriminator(gen_imgs))\n",
        "\n",
        "      loss_G.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "      print(\n",
        "        \"[Epoch %d/%d][Batch %d/%d][D loss: %f] [G loss: %f]\"\n",
        "        % (epoch, NUM_EPOCHS, batches_done % len(dataloader), len(dataloader), loss_D.item(), loss_G.item())\n",
        "      )   \n",
        "      batches_done += D_N_TRAIN\n",
        "\n",
        "  # Check how the generator is doing by saving G's output on fixed_noise\n",
        "  if (epoch % (NUM_EPOCHS / 50) == 0) or ((epoch == NUM_EPOCHS - 1) and (i == len(dataloader) - 1)):\n",
        "    with torch.no_grad():\n",
        "      fake = generator(fixed_noise).detach().cpu()\n",
        "      img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj_7LrhooyZK",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adeNRznT23bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvXQH8MW23bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2gWvS4kPYQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save images\n",
        "#plt.figure(figsize=(15,15))\n",
        "#plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "#plt.savefig(os.path.join(PATH_NOTEBOOK, \"wow.png\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSJzqt83clsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate random pokemons\n",
        "num_pokemons = 3\n",
        "latent_vectors = torch.randn(num_pokemons, LATENT_VECTOR_SIZE, 1, 1, device=device)\n",
        "pokemons = generator(latent_vectors).detach().cpu()\n",
        "\n",
        "for i in range(num_pokemons):\n",
        "  plt.figure()\n",
        "  plt.imshow(np.transpose(vutils.make_grid(pokemons.to(device)[i], padding=5, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5inoV4pvmv3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}